{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "581c95bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from string import punctuation\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b955ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    df = None\n",
    "    df=pd.read_csv(\"TRAIN_balanced_ham_spam.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3625f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(df):\n",
    "    ham_prior = 0\n",
    "    spam_prior =  0\n",
    "    ham_prior=df[\"label\"].value_counts()[0]/df.shape[0]\n",
    "    spam_prior=df[\"label\"].value_counts()[1]/df.shape[0]\n",
    "    \n",
    "    return ham_prior, spam_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bfc7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(df):\n",
    "    ham_like_dict = {}\n",
    "    spam_like_dict = {}\n",
    "    for i in range(df[\"label\"].value_counts()[0]):\n",
    "        content=df.iloc[i,3].split()\n",
    "        #make sure each word only be counted one time per email\n",
    "        email=list(OrderedDict.fromkeys(content))  \n",
    "        for word in email:\n",
    "            if word.lower() not in ham_like_dict and word not in punctuation:\n",
    "                ham_like_dict[word] = 1\n",
    "            elif word.lower() in ham_like_dict:\n",
    "                ham_like_dict[word] = ham_like_dict.get(word) + 1\n",
    "                \n",
    "    # get item in dictionary as likelihood probability for ham dictiionary\n",
    "    for word in ham_like_dict:  \n",
    "        ham_like_dict[word]=ham_like_dict.get(word)/df[\"label\"].value_counts()[0]\n",
    "    \n",
    "    for j in range(df[\"label\"].value_counts()[0],df.shape[0]):\n",
    "        content=df.iloc[j,3].split()\n",
    "        email=list(OrderedDict.fromkeys(content))\n",
    "        for word in email:\n",
    "            if word.lower() not in spam_like_dict and word not in punctuation:\n",
    "                spam_like_dict[word] = 1\n",
    "            elif word.lower() in spam_like_dict:\n",
    "                spam_like_dict[word] = spam_like_dict.get(word) + 1    \n",
    "    \n",
    "    for word in spam_like_dict:\n",
    "        spam_like_dict[word]=spam_like_dict.get(word)/df[\"label\"].value_counts()[0]\n",
    "    \n",
    "          \n",
    "        \n",
    "                \n",
    "    return ham_like_dict, spam_like_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1861076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ham_prior, spam_prior, ham_like_dict, spam_like_dict, text):\n",
    "    '''\n",
    "    prediction function that uses prior and likelihood structure to compute proportional posterior for a single line of text\n",
    "    '''\n",
    "    text=text.split() # split word string in to a list of seperate words\n",
    "    ham_likelihood=0\n",
    "    f_list=[\"for\",\"to\",\"the\",\"on\",\"a\",\"and\",\"you\",\"is\",\"this\",\"of\",\"i\",\"with\",\"this\"] #word list that words are too frequently appear\n",
    "    #caculate the log likelihood of given class=ham\n",
    "    for word in text:\n",
    "        if word in ham_like_dict and word not in f_list:\n",
    "            ham_likelihood =ham_likelihood+ np.log(ham_like_dict.get(word))\n",
    "        else:\n",
    "            ham_likelihood =ham_likelihood+ np.log(0.0001)     #mupltiply by a very samll probabiliyt for ward not appearing \n",
    "    #caculate the log likelihood of given class=spam\n",
    "    spam_likelihood=0\n",
    " \n",
    "    for word in text:\n",
    "        if word in spam_like_dict and word not in f_list:\n",
    "            spam_likelihood =spam_likelihood+ np.log(spam_like_dict.get(word))\n",
    "        else:\n",
    "            spam_likelihood =spam_likelihood+ np.log(0.0001)\n",
    "    #ham_spam_decision = 1 if classified as spam, 0 if classified as normal/ham\n",
    "    ham_spam_decision = None\n",
    "    \n",
    "    \n",
    "    #ham_posterior = posterior probability that the email is normal/ham\n",
    "\n",
    "    ham_posterior = None\n",
    "    #spam_posterior = posterior probability that the email is spam\n",
    "\n",
    "    spam_posterior = None\n",
    "    ham_posterior = ham_likelihood+np.log(ham_prior)\n",
    "    spam_posterior = spam_likelihood+np.log(spam_prior)\n",
    "    if ham_posterior>= spam_posterior:\n",
    "        ham_spam_decision=0\n",
    "    else:\n",
    "        ham_spam_decision=1\n",
    "    \n",
    "    return ham_spam_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091ef2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(ham_prior, spam_prior, ham_dict, spam_dict, df):\n",
    "    '''\n",
    "    Calls \"predict\"\n",
    "    '''\n",
    "    hh = 0 #true negatives, truth = ham, predicted = ham\n",
    "    hs = 0 #false positives, truth = ham, pred = spam\n",
    "    sh = 0 #false negatives, truth = spam, pred = ham\n",
    "    ss = 0 #true positives, truth = spam, pred = spam\n",
    "    num_rows = df.shape[0]\n",
    "    for i in range(num_rows):\n",
    "        roi = df.iloc[i,:]\n",
    "        roi_text = roi.text\n",
    "        roi_label = roi.label_num\n",
    "        guess = predict(ham_prior, spam_prior, ham_dict, spam_dict, roi_text)\n",
    "        if roi_label == 0 and guess == 0:\n",
    "            hh += 1\n",
    "        elif roi_label == 0 and guess == 1:\n",
    "            hs += 1\n",
    "        elif roi_label == 1 and guess == 0:\n",
    "            sh += 1\n",
    "        elif roi_label == 1 and guess == 1:\n",
    "            ss += 1\n",
    "    \n",
    "    acc = (ss + hh)/(ss+hh+sh+hs)\n",
    "    precision = (ss)/(ss + hs)\n",
    "    recall = (ss)/(ss + sh)\n",
    "    return acc, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e2050f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9783333333333334, 0.9644012944983819, 0.9933333333333333)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df=load(1)\n",
    "    ham_prior, spam_prior=prior(df)\n",
    "    ham_dict, spam_dict=likelihood(df)\n",
    "    test_df=pd.read_csv(\"TEST_balanced_ham_spam.csv\")\n",
    "    print(metrics(ham_prior, spam_prior, ham_dict, spam_dict,test_df))\n",
    "\t#this cell is for your own testing of the functions above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa3e671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(a.items(), key=lambda x: x[1], reverse=True) a is a dictionary and I arrange the dictionary in descending order\n",
    "#sorted(b.items(), key=lambda x: x[1], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
